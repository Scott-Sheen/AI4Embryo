{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mxnet_ResNet50_v2_DIC_AIF_DTCWT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbT7e0zraRT8"
      },
      "source": [
        "### Mount my Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR_SN-b_J2YR"
      },
      "source": [
        "import os\n",
        "from google.colab import files, drive   \n",
        "\n",
        "# mount the google drive to my Colab session\n",
        "drive.mount('/content/gdrive')\n",
        "print(os.listdir('/content/gdrive/My Drive/'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvWktmgGG49n"
      },
      "source": [
        "### Install MXNet and GluonCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "438ei1pTEnVs"
      },
      "source": [
        "!pip install --upgrade mxnet-cu101 gluoncv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO0UuwyTbQME"
      },
      "source": [
        "### Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj54W_2nD_5O"
      },
      "source": [
        "import mxnet as mx\n",
        "import numpy as np\n",
        "import os, time, shutil\n",
        "\n",
        "from mxnet import gluon, image, init, nd\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.utils import makedirs, TrainingHistory\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adzu6uFyfsiZ",
        "outputId": "1416efed-80ca-4cde-b7c4-c759f3306832"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fs = 20\n",
        "!wget https://github.com/trishume/OpenTuringCompiler/raw/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
        "fm.fontManager.ttflist += fm.createFontList(['Times New Roman.ttf'])\n",
        "mpl.rc('font', family='Times New Roman', size=fs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-20 22:10:40--  https://github.com/trishume/OpenTuringCompiler/raw/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/trishume/OpenTuringCompiler/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf [following]\n",
            "--2021-05-20 22:10:41--  https://raw.githubusercontent.com/trishume/OpenTuringCompiler/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 834452 (815K) [application/octet-stream]\n",
            "Saving to: ‘Times New Roman.ttf’\n",
            "\n",
            "Times New Roman.ttf 100%[===================>] 814.89K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-20 22:10:41 (12.8 MB/s) - ‘Times New Roman.ttf’ saved [834452/834452]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: \n",
            "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaRRaxYZGc57"
      },
      "source": [
        "### Data preparation & Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkEM543utI1U"
      },
      "source": [
        "path = '/content/gdrive/My Drive/embryo-89-8cell-DIC_AIF_DTCWT-onset'\n",
        "\n",
        "train_path = os.path.join(path, 'train')\n",
        "test_path = os.path.join(path, 'validate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEUXwgimCtkx",
        "outputId": "46b8a50a-c840-4094-ef72-cec60e25a25c"
      },
      "source": [
        "npzfile = np.load(os.path.join(path, 'train_mean_std.npz'))\n",
        "X_mean = npzfile['X_mean'].tolist()\n",
        "X_std = npzfile['X_std'].tolist()\n",
        "print(X_mean,X_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128.17645593242332 42.19776721563477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No9skYntHZ1i"
      },
      "source": [
        "# z-score standardize the data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(600, keep_ratio=True),\n",
        "    transforms.CenterCrop(512),\n",
        "\n",
        "    transforms.RandomFlipLeftRight(), # Randomly flip the image horizontally\n",
        "    transforms.RandomFlipTopBottom(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomRotation((-15, 15),rotate_with_proba=0.5),\n",
        "    transforms.Normalize([X_mean], [X_std])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(600, keep_ratio=True),\n",
        "    transforms.CenterCrop(512),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([X_mean], [X_std])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHDHbb11bmsJ"
      },
      "source": [
        "### Set hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6TqVtnkbkfO"
      },
      "source": [
        "classes = 2\n",
        "\n",
        "per_device_batch_size = 16\n",
        "num_gpus = 1\n",
        "num_workers = 8\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
        "batch_size = per_device_batch_size * max(num_gpus, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cOz_wQb90nQ"
      },
      "source": [
        "### Define data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEQW9bM69157"
      },
      "source": [
        "train_data = gluon.data.DataLoader(\n",
        "    gluon.data.vision.ImageFolderDataset(train_path).transform_first(transform_train),\n",
        "    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "test_data = gluon.data.DataLoader(\n",
        "    gluon.data.vision.ImageFolderDataset(test_path).transform_first(transform_test),\n",
        "    batch_size=batch_size, shuffle=False, num_workers = num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md_EE4hm7jGk"
      },
      "source": [
        "### Optimizer, Loss and Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN3PnzanPQ81"
      },
      "source": [
        "lr = 1e-3\n",
        "lr_factor = 0.75 # Learning rate decay factor\n",
        "lr_steps = [10, 20, 30, np.inf] # Epochs where learning rate decays\n",
        "wd = 0.0001\n",
        "momentum = 0.9\n",
        "\n",
        "# optimizer = 'sgd' # 'nag': Nesterov accelerated gradient descent\n",
        "# optimizer_params = {'learning_rate': lr, 'wd': wd, 'momentum': momentum} # Set parameters\n",
        "\n",
        "optimizer = 'adam'\n",
        "optimizer_params = {'learning_rate': lr} # Set parameters\n",
        "\n",
        "L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc', 'validation-acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCL97vJFGoak"
      },
      "source": [
        "# define an evaluation function for validation and testing\n",
        "def test(net, test_data, ctx):\n",
        "    metric = mx.metric.Accuracy()\n",
        "    for i, batch in enumerate(test_data):\n",
        "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "        outputs = [net(X) for X in data]\n",
        "        metric.update(label, outputs)\n",
        "\n",
        "    return metric.get()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KK1835Gsgkf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbhc_OErHae3"
      },
      "source": [
        "for idx in range(1,4,1):\n",
        "  epochs = 40\n",
        "  lr_counter = 0\n",
        "  num_batch = len(train_data)\n",
        "  train_acc_list = []\n",
        "  val_acc_list = []\n",
        "\n",
        "  model_name = 'ResNet50_v2'\n",
        "  # Fine-tuning pre-trained models: train model on my new data using the pre-trained weights as initialization -- transfer learning\n",
        "  finetune_net = get_model(model_name, pretrained=True)\n",
        "  with finetune_net.name_scope():\n",
        "      finetune_net.output = nn.Dense(classes)\n",
        "\n",
        "  finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
        "  finetune_net.collect_params().reset_ctx(ctx)\n",
        "  finetune_net.hybridize()\n",
        "\n",
        "  trainer = gluon.Trainer(finetune_net.collect_params(), optimizer, optimizer_params)\n",
        "\n",
        "  # training loop\n",
        "  for epoch in range(epochs):\n",
        "      if epoch == lr_steps[lr_counter]:\n",
        "          trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n",
        "          lr_counter += 1\n",
        "\n",
        "      tic = time.time()\n",
        "      train_loss = 0\n",
        "      metric.reset()\n",
        "\n",
        "      for i, batch in enumerate(train_data):\n",
        "          data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "          label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "          with ag.record():\n",
        "              outputs = [finetune_net(X) for X in data]\n",
        "              loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
        "          for l in loss:\n",
        "              l.backward()\n",
        "\n",
        "          trainer.step(batch_size)\n",
        "          train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
        "\n",
        "          metric.update(label, outputs)\n",
        "\n",
        "      _, train_acc = metric.get()\n",
        "      train_loss /= num_batch\n",
        "\n",
        "      _, val_acc = test(finetune_net, test_data, ctx)\n",
        "      train_history.update([train_acc, val_acc])\n",
        "      train_acc_list.append(train_acc)\n",
        "      val_acc_list.append(val_acc)\n",
        "\n",
        "      print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc: %.3f | time: %.1f' %\n",
        "              (epoch, train_acc, train_loss, val_acc, time.time() - tic))\n",
        "\n",
        "  train_history.plot(['training-acc', 'validation-acc'])\n",
        "  # save model parameters\n",
        "  model_file_name = '/content/gdrive/My Drive/ResNet50_v2_weights_DIC_AIF_DTCWT/trial'+str(idx)+'.params'\n",
        "  finetune_net.save_parameters(model_file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}